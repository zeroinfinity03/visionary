<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blind Assistance App</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <style>
        @keyframes pulsate {
            0% { transform: scale(1); opacity: 0.7; }
            50% { transform: scale(1.1); opacity: 0.3; }
            100% { transform: scale(1); opacity: 0.7; }
        }
        .mic-button-wrapper {
            position: relative;
            display: inline-block;
            width: 100px;
            height: 100px;
        }
        .mic-button {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 2;
            background-color: white;
            border-radius: 50%;
            padding: 0.5rem;
            width: 80px;
            height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .mic-button-wrapper::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            border-radius: 50%;
            background-color: #3B82F6; /* Tailwind blue-500 */
            z-index: 1;
            opacity: 0;
            transition: opacity 0.3s ease-in-out;
        }
        .mic-button-wrapper.recording::before {
            opacity: 1;
            animation: pulsate 1.5s ease-in-out infinite;
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen flex items-center justify-center p-4" onload="startApp()">
    <div id="app" class="w-full max-w-md bg-white rounded-xl shadow-md overflow-hidden">
        <div class="p-6 space-y-6">
            <div class="text-center">
                <div id="micBtnWrapper" class="mic-button-wrapper">
                    <button id="micBtn" class="mic-button text-4xl text-blue-500 hover:text-blue-600 transition-all duration-300 ease-in-out">
                        <i class="fas fa-microphone"></i>
                    </button>
                </div>
            </div>
            <div class="relative w-full" style="height: 300px;">
                <video id="video" class="absolute inset-0 w-full h-full object-cover rounded-lg"></video>
            </div>
        </div>
    </div>

    <script>
        const micBtn = document.getElementById('micBtn');
        const micBtnWrapper = document.getElementById('micBtnWrapper');
        const video = document.getElementById('video');
        let audioStream = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let shakeThreshold = 15;
        let lastX = 0, lastY = 0, lastZ = 0;

        async function startApp() {
            try {
                const videoStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    },
                    audio: false  // Disable audio for video stream
                });
                video.srcObject = videoStream;
                await video.play();

                await new Promise((resolve, reject) => {
                    navigator.geolocation.getCurrentPosition(resolve, reject);
                });

                setupShakeDetection();
                console.log('App started successfully');
            } catch (error) {
                console.error('Error:', error);
            }
        }

        function setupShakeDetection() {
            window.addEventListener('devicemotion', (event) => {
                let acceleration = event.accelerationIncludingGravity;
                let curX = acceleration.x;
                let curY = acceleration.y;
                let curZ = acceleration.z;
                
                let change = Math.abs(curX + curY + curZ - lastX - lastY - lastZ);
                if (change > shakeThreshold) {
                    toggleRecording();
                }
                
                lastX = curX;
                lastY = curY;
                lastZ = curZ;
            });
        }

        async function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        async function startRecording() {
            try {
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(audioStream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = sendAudioToBackend;

                mediaRecorder.start();
                isRecording = true;
                micBtnWrapper.classList.add('recording');
                micBtn.querySelector('i').classList.add('text-red-500');
                micBtn.querySelector('i').classList.remove('text-blue-500', 'hover:text-blue-600');
            } catch (error) {
                console.error('Error starting recording:', error);
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                micBtnWrapper.classList.remove('recording');
                micBtn.querySelector('i').classList.remove('text-red-500');
                micBtn.querySelector('i').classList.add('text-blue-500', 'hover:text-blue-600');
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                    audioStream = null;
                }
            }
        }

        let speechSynthesis = window.speechSynthesis;
        let speaking = false;

        async function sendAudioToBackend() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');

            try {
                const response = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });
                const result = await response.json();
                console.log('Gemini response:', result);

                if (result.capture_image) {
                    await captureAndSendImage();
                } else if (result.is_navigation) {
                    handleNavigation(result.response);
                } else {
                    speakResponse(result.response);
                }
            } catch (error) {
                console.error('Error sending audio to backend:', error);
            }
        }

        function handleNavigation(response) {
            let destination = response.replace('opening google map, for', '').replace('in dah put the location.', '').trim();
            if (!destination) {
                destination = "nearby places";
            }
            speakResponse(`Starting navigation to ${destination}`);
            
            // Get current location
            navigator.geolocation.getCurrentPosition((position) => {
                const { latitude, longitude } = position.coords;
                let mapsUrl;
                
                // Check if it's a mobile device
                if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
                    // For mobile devices, use URL scheme to start turn-by-turn navigation
                    mapsUrl = `google.navigation:q=${encodeURIComponent(destination)}&mode=w`;  // 'w' for walking mode
                    window.location.href = mapsUrl;
                    
                    // Fallback to opening in a new tab if the app doesn't open
                    setTimeout(() => {
                        mapsUrl = `https://www.google.com/maps/dir/${latitude},${longitude}/${encodeURIComponent(destination)}`;
                        window.open(mapsUrl, '_blank');
                    }, 1000);
                } else {
                    // For desktop, open directions in a new tab
                    mapsUrl = `https://www.google.com/maps/dir/${latitude},${longitude}/${encodeURIComponent(destination)}`;
                    window.open(mapsUrl, '_blank');
                }
            }, (error) => {
                console.error('Error getting location:', error);
                // Fallback to just opening Google Maps with the destination
                const mapsUrl = `https://www.google.com/maps/search/${encodeURIComponent(destination)}`;
                window.open(mapsUrl, '_blank');
            });
        }

        async function captureAndSendImage() {
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const imageBlob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));

            const formData = new FormData();
            formData.append('image', imageBlob, 'capture.jpg');

            try {
                const response = await fetch('/process_image', {
                    method: 'POST',
                    body: formData
                });
                const result = await response.json();
                speakResponse(result.response);
            } catch (error) {
                console.error('Error sending image to backend:', error);
            }
        }

        function speakResponse(text) {
            if (speaking) {
                speechSynthesis.cancel();
            }

            const speech = new SpeechSynthesisUtterance(text);
            
            speech.onstart = () => {
                speaking = true;
                console.log('Speech started');
            };
            
            speech.onend = () => {
                speaking = false;
                console.log('Speech ended');
            };

            speechSynthesis.speak(speech);
        }

        micBtn.addEventListener('click', toggleRecording);
    </script>
</body>
</html>


